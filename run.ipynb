{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import tiktoken\n",
    "\n",
    "encode = tiktoken.encoding_for_model(\"gpt-3.5-turbo\").encode\n",
    "count_token = lambda x: len(encode(x))\n",
    "\n",
    "def remove_ignored_dirs(dirs, ignore_dirs):\n",
    "    dirs[:] = [dir for dir in dirs if dir not in ignore_dirs]\n",
    "\n",
    "\n",
    "def generate_tree(start_path: str, ignore_dirs: list, indent_size: int = 1) -> str:\n",
    "    tree_lines = []\n",
    "    for root, dirs, files in os.walk(start_path):\n",
    "        remove_ignored_dirs(dirs, ignore_dirs)\n",
    "        level = root.replace(start_path, '').count(os.sep)\n",
    "        indent = ' ' * indent_size * level\n",
    "        tree_lines.append(f\"{indent}{os.path.basename(root)}/\")\n",
    "        sub_indent = ' ' * indent_size * (level + 1)\n",
    "        tree_lines.extend(f\"{sub_indent}{f}\" for f in files)\n",
    "    return '\\n'.join(tree_lines[:-1])\n",
    "\n",
    "FILE_EXTENSION_LANG_MAP = {\n",
    "    \".py\": \"python\",\n",
    "    \".js\": \"javascript\",\n",
    "    \".ts\": \"typescript\",\n",
    "    \".java\": \"java\",\n",
    "    \".c\": \"c\",\n",
    "    \".cpp\": \"cpp\",\n",
    "    \".cs\": \"csharp\",\n",
    "    \".php\": \"php\",\n",
    "    \".rb\": \"ruby\",\n",
    "    \".swift\": \"swift\",\n",
    "    \".go\": \"go\",\n",
    "    \".r\": \"r\",\n",
    "    \".m\": \"objective-c\",\n",
    "    \".pl\": \"perl\",\n",
    "    \".md\": \"markdown\",\n",
    "    \".tsx\": \"typescript\",\n",
    "    \".jsx\": \"javascript\",\n",
    "}\n",
    "COMMENT_SYMBOL_MAP = {\n",
    "    \"python\": \"#\",\n",
    "    \"javascript\": \"//\",\n",
    "    \"typescript\": \"//\",\n",
    "    \"java\": \"//\",\n",
    "    \"c\": \"//\",\n",
    "    \"cpp\": \"//\",\n",
    "    \"csharp\": \"//\",\n",
    "    \"php\": \"//\",\n",
    "    \"ruby\": \"#\",\n",
    "    \"swift\": \"//\",\n",
    "    \"go\": \"//\",\n",
    "    \"r\": \"#\",\n",
    "    \"objective-c\": \"//\",\n",
    "    \"perl\": \"#\",\n",
    "    \"css\": \"/*\"\n",
    "}\n",
    "\n",
    "def get_lang_from_extension(file_extension: str) -> str:\n",
    "    return FILE_EXTENSION_LANG_MAP.get(file_extension, file_extension[1:])\n",
    "\n",
    "def process_file(root: str, file: str, relative_path: str, no_formatting: bool, print_token_counts: bool):\n",
    "    lang = get_lang_from_extension(os.path.splitext(file)[-1])\n",
    "    comment_symbol = COMMENT_SYMBOL_MAP.get(lang, \"//\")\n",
    "\n",
    "    try:\n",
    "        with open(os.path.join(root, file), \"r\", encoding='utf-8') as infile:\n",
    "            data = infile.read()\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Error reading {relative_path}\")\n",
    "        return None\n",
    "\n",
    "    if no_formatting:\n",
    "        comment_pattern = re.escape(comment_symbol) + '.*$'\n",
    "        data = re.sub(comment_pattern, ' ', data, flags=re.MULTILINE)\n",
    "        data = re.sub(r'(?<=\\n)[ \\t]*(?=\\n)', '', data)\n",
    "        # remove all newlines\n",
    "        data = re.sub(r'\\n', ' ', data)\n",
    "        data = re.sub(r';+', '; ', data)\n",
    "        data = re.sub(r' +', ' ', data)\n",
    "\n",
    "    token_count = count_token(data) + count_token(relative_path) if print_token_counts else 0\n",
    "\n",
    "    return {\n",
    "        \"path\": relative_path,\n",
    "        \"token_count\": token_count,\n",
    "        \"data\": data,\n",
    "        \"comment_symbol\": comment_symbol,\n",
    "        \"lang\": lang\n",
    "    }\n",
    "\n",
    "def walk_files(config: dict):\n",
    "    cwd = os.getcwd()\n",
    "    outputs = []\n",
    "\n",
    "    zero_target_files = not config[\"target_files\"]\n",
    "    zero_allowed_extensions = not config[\"allowed_extensions\"]\n",
    "\n",
    "    for root, dirs, files in os.walk(config['path']):\n",
    "        remove_ignored_dirs(dirs, config['ignore_dirs'])\n",
    "\n",
    "        for file in files:\n",
    "            if zero_allowed_extensions or (file.endswith(config['allowed_extensions']) and not file.endswith(config['ignored_extensions'])):\n",
    "                if file in config['ignore_files']:\n",
    "                    continue\n",
    "                if zero_target_files or file in config['target_files']:\n",
    "                    relative_path = f'{root.replace(cwd, \"\")}/{file}'\n",
    "                    if relative_path[0] == '/':\n",
    "                        relative_path = relative_path[1:]\n",
    "\n",
    "                    output = process_file(root, file, relative_path, config['no_formatting'], config['print_token_counts'])\n",
    "                    if output and output['data']:\n",
    "                        outputs.append(output)\n",
    "\n",
    "    outputs = sorted(outputs, key=lambda x: os.path.splitext(x['path'])[-1])\n",
    "    sept = '\\n\\n---\\n\\n'\n",
    "    tree = generate_tree(config['path'], config['ignore_dirs'], indent_size=2) + sept\n",
    "    generate_output_content = lambda x: f\"```{x['lang']}\\n{x['comment_symbol']} {x['path']}\\n{x['data']}\\n```\"\n",
    "\n",
    "    if config['print_token_counts']:\n",
    "        out_string = tree + sept.join([f\"count: {x['token_count']}\\n{generate_output_content(x)}\" for x in outputs])\n",
    "    else:\n",
    "        out_string = tree + sept.join([generate_output_content(x) for x in outputs])\n",
    "\n",
    "    total_tokens = count_token(out_string)\n",
    "\n",
    "    with open(config['output_file'], \"w\", encoding='utf-8') as outfile:\n",
    "        outfile.write(f'total: {total_tokens}\\n\\n{out_string}')\n",
    "\n",
    "config = {\n",
    "    'path': os.getcwd(), #\"src/components/game\", #\n",
    "    'output_file': \"output.txt\",\n",
    "    'target_files': [ \"App.tsx\", \"index.tsx\"], # [],\n",
    "    'allowed_extensions': (), \n",
    "    'ignored_extensions': (),\n",
    "    'print_token_counts': False,\n",
    "    'no_formatting': True,\n",
    "    'ignore_dirs': [\"favicon\", \".husky\", \".next\", \"node_modules\", \".git\", \".vscode\", \"__pycache__\", \"old\", \"test_page\", \"dist\"],\n",
    "    'ignore_files': [\"example.ts\", \"output.txt\", \"yarn.lock\", \"package-lock.json\", \"package.json\", \"tsconfig.json\", \"run.ipynb\", \"tailwind.config.cjs\"],\n",
    "}\n",
    "\n",
    "walk_files(config)\n",
    "os.system(\"code output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://ls7ojkm1lh.execute-api.us-west-2.amazonaws.com/Prod'\n",
    "# headers = {\n",
    "#     \"Content-Type\": \"application/json\",\n",
    "#     \"x-api-key\": \"evEol4JklL9AGHHijU03j4kGctKFg79d3tJb1zBh\",\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159416\n",
      "{'error': 'Unexpected error: can only concatenate str (not \"NoneType\") to str'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import json\n",
    "import base64\n",
    "\n",
    "# load old/devEnv/base64/example.txt\n",
    "with open('old/devEnv/base64/example.txt', 'r') as f:\n",
    "    base64_audio = f.read()\n",
    "    \n",
    "print(len(base64_audio))\n",
    "\n",
    "# lang = 'hi'\n",
    "lang = 'pt'\n",
    "# lang = 'ko'\n",
    "\n",
    "url = 'https://dyhweydzb4ws7peuxwmy5dzifm0zhnww.lambda-url.us-west-2.on.aws/'\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"audioData\": base64_audio,\n",
    "    \"startTime\": 0,\n",
    "    \"endTime\": 10,\n",
    "    \"sourceLanguage\": \"en\",\n",
    "    \"targetLanguage\": lang,\n",
    "    \"videoURL\": \"http://example.com/video.mp4\",\n",
    "    \"videoId\": \"test\"\n",
    "}\n",
    "\n",
    "jsonData = json.dumps(data)\n",
    "response = requests.post(url, headers=headers, data=jsonData)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    content = response.json()\n",
    "    print(response.__dict__)\n",
    "    audioDataTrans = content['audioData']\n",
    "    # convert back into binary\n",
    "    audioDataTrans = base64.b64decode(audioDataTrans)\n",
    "    # save to mp3 file\n",
    "    outpit_file_name = f'old/devEnv/test_audio_{lang}.mp3'\n",
    "    with open(outpit_file_name, 'wb') as f:\n",
    "        f.write(audioDataTrans)\n",
    "    print('success')\n",
    "else:\n",
    "    print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Unknown file type'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "import filetype\n",
    "import re\n",
    "\n",
    "def identify_file_type(base64_string):\n",
    "    # Decode the base64 string to bytes\n",
    "    actual_base64_data = base64_string.split(\",\")[-1]\n",
    "    \n",
    "    # Check if padding adjustment is necessary\n",
    "    missing_padding = len(actual_base64_data) % 4\n",
    "    if missing_padding:\n",
    "        actual_base64_data += '=' * (4 - missing_padding)\n",
    "    \n",
    "    # Ensure the base64 string is valid\n",
    "    if not re.fullmatch(r'[A-Za-z0-9+/]*={0,2}', actual_base64_data):\n",
    "        return \"Invalid base64 string\"\n",
    "\n",
    "    binary_data = base64.b64decode(actual_base64_data)\n",
    "    \n",
    "    kind = filetype.guess(binary_data)\n",
    "\n",
    "    if kind is None:\n",
    "        return \"Unknown file type\"\n",
    "    else:\n",
    "        return kind.extension\n",
    "\n",
    "\n",
    "with open('old/devEnv/base64/example.txt', 'r') as f:\n",
    "    base64_audio = f.read()\n",
    "    \n",
    "identify_file_type(base64_audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_extension(mime_type_str):\n",
    "    codec_to_extension_map = {\n",
    "        'opus': '.opus',\n",
    "        'vorbis': '.ogg',\n",
    "        'mp4a.40.2': '.m4a',\n",
    "        'mpeg3': '.mp3',\n",
    "        'flac': '.flac',\n",
    "        'alac': '.m4a',\n",
    "        '1': '.wav',    # PCM codec for wav\n",
    "        'samr': '.amr',\n",
    "        'mp4v.20.8': '.mp4',\n",
    "        'XVID': '.avi',\n",
    "        'wmv3': '.wmv',\n",
    "        'vp9': '.webm',\n",
    "        'vp8': '.webm',\n",
    "        'V_MPEG4/ISO/AVC': '.mkv',\n",
    "        'theora': '.ogg',\n",
    "        'mpeg1video': '.mpg',\n",
    "        'A_AAC': '.aac',\n",
    "        'oga': '.oga'    # Ogg Vorbis audio\n",
    "    }\n",
    "\n",
    "    # Split on semicolon to get the base mime type and parameters\n",
    "    parts = mime_type_str.split(';')\n",
    "    base_mime_type = parts[0]\n",
    "    base_type, subtype = base_mime_type.split('/')\n",
    "\n",
    "    # If there's no semicolon, we guess the extension based on the subtype\n",
    "    if len(parts) < 2:\n",
    "        return codec_to_extension_map.get(subtype, f\".{subtype}\")\n",
    "\n",
    "    params = parts[1]\n",
    "    \n",
    "    # Extract the codec from the parameters, if it exists\n",
    "    if 'codecs=' in params:\n",
    "        codecs = params.split('codecs=')[1].replace('\"', '').split(',')\n",
    "        \n",
    "        # if there are multiple codecs, we assume the second one is the audio codec\n",
    "        if len(codecs) > 1:\n",
    "            audio_codec = codecs[1].strip()\n",
    "        else:\n",
    "            audio_codec = codecs[0].strip()\n",
    "            \n",
    "        return codec_to_extension_map.get(audio_codec, f\".{subtype}\")\n",
    "\n",
    "    # If there's no codec, return based on the subtype\n",
    "    else:\n",
    "        return codec_to_extension_map.get(subtype, f\".{subtype}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_mime_types = [\n",
    "    'video/webm; codecs=\"vp9, opus\"',\n",
    "    'video/mp4; codecs=\"avc1.42E01E, mp4a.40.2\"',\n",
    "    'video/avc; codecs=\"avc1.42E01E, mp4a.40.2\"',\n",
    "    'video/webm; codecs=\"vp8, vorbis\"',\n",
    "    'video/mp4; codecs=\"hev1.1.2.L93.B0, mp4a.40.2\"',\n",
    "    'video/quicktime; codecs=\"avc1.42E01E, mp4a.40.2\"',\n",
    "    'video/x-matroska; codecs=\"V_MPEG4/ISO/AVC, A_AAC\"',\n",
    "    'video/ogg; codecs=\"theora, vorbis\"',\n",
    "    'video/3gpp; codecs=\"mp4v.20.8, samr\"',\n",
    "    'video/mpeg; codecs=\"mpeg1video\"',\n",
    "    'video/x-m4v; codecs=\"avc1.42E01E, mp4a.40.2\"',\n",
    "    'video/x-msvideo; codecs=\"XVID\"',\n",
    "    'video/x-ms-wmv; codecs=\"wmv3\"',\n",
    "]\n",
    "\n",
    "audioMimeTypes = [\n",
    "  \"audio/webm; codecs=opus\",          \n",
    "  \"audio/mp4; codecs=mp4a.40.2\",      \n",
    "  \"audio/aac; codecs=mp4a.40.2\",      \n",
    "  \"audio/mpeg; codecs=mpeg3\",\n",
    "  \"audio/ogg; codecs=vorbis\",\n",
    "  \"audio/flac\",\n",
    "  \"audio/alac\",\n",
    "  \"audio/wav; codecs=1\", \n",
    "  \"audio/amr\",\n",
    "]\n",
    "\n",
    "# test every mime type and print the result\n",
    "for mime_type_str in video_mime_types + audioMimeTypes:\n",
    "    audio_extension = get_audio_extension(mime_type_str)\n",
    "    print(f'{mime_type_str} -> {audio_extension}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytube\n",
    "\n",
    "url = 'https://www.youtube.com/watch?v=VTOO_9_ECA8'\n",
    "\n",
    "video = pytube.YouTube(url)\n",
    "streams = video.streams\n",
    "\n",
    "# download the video\n",
    "video.streams.get_highest_resolution().download()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy\n",
    "# vid.mp4\n",
    "\n",
    "# Get 59s to 1:22s\n",
    "\n",
    "# load with moviepy\n",
    "from moviepy.editor import VideoFileClip\n",
    "clip = VideoFileClip(\"vid.mp4\").subclip(59, 82)\n",
    "\n",
    "# save as mp4\n",
    "clip.write_videofile(\"vid2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the magic numbers for common audio file formats\n",
    "magic_numbers = {\n",
    "    \"mp3\": [\"494433\", \"fff3\", \"fffb\"],\n",
    "    \"wav\": [\"52494646\"],\n",
    "    \"ogg\": [\"4f676753\"],\n",
    "    \"flac\": [\"664c6143\"],\n",
    "    \"aac\": [\"fff1\", \"fff9\", \"fff3\", \"fffd\"],\n",
    "    \"wma\": [\"3026b275\"],\n",
    "    \"midi\": [\"4d546864\"],\n",
    "    \"aiff\": [\"464f524d\"],\n",
    "}\n",
    "\n",
    "# Convert the first few bytes of the binary content to hexadecimal\n",
    "hex_signature = binary_content[:4].hex()\n",
    "\n",
    "# Function to identify the file type from the magic number\n",
    "def identify_file_type(hex_signature, magic_numbers):\n",
    "    for file_type, signatures in magic_numbers.items():\n",
    "        if any(hex_signature.startswith(sig) for sig in signatures):\n",
    "            return file_type\n",
    "    return \"Unknown file type\"\n",
    "\n",
    "# Identify the file type\n",
    "file_type = identify_file_type(hex_signature, magic_numbers)\n",
    "file_type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// Define the magic numbers for common audio file formats\n",
    "const magicNumbers: { [key: string]: string[] } = {\n",
    "    mp3: [\"494433\", \"fff3\", \"fffb\"],\n",
    "    wav: [\"52494646\"],\n",
    "    ogg: [\"4f676753\"],\n",
    "    flac: [\"664c6143\"],\n",
    "    aac: [\"fff1\", \"fff9\", \"fff3\", \"fffd\"],\n",
    "    wma: [\"3026b275\"],\n",
    "    midi: [\"4d546864\"],\n",
    "    aiff: [\"464f524d\"],\n",
    "};\n",
    "\n",
    "// Assume you have binaryContent as an ArrayBuffer or Buffer\n",
    "// Convert the first few bytes of the binary content to hexadecimal\n",
    "const hexSignature = binaryContent.slice(0, 4).toString('hex');\n",
    "\n",
    "// Function to identify the file type from the magic number\n",
    "function identifyFileType(hexSignature: string, magicNumbers: { [key: string]: string[] }): string {\n",
    "    for (const [fileType, signatures] of Object.entries(magicNumbers)) {\n",
    "        if (signatures.some(sig => hexSignature.startsWith(sig))) {\n",
    "            return fileType;\n",
    "        }\n",
    "    }\n",
    "    return \"Unknown file type\";\n",
    "}\n",
    "\n",
    "// Identify the file type\n",
    "const fileType = identifyFileType(hexSignature, magicNumbers);\n",
    "console.log(fileType);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install filetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]),\n",
       " (2, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096]),\n",
       " (3, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]),\n",
       " (4, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192]),\n",
       " (5, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]),\n",
       " (6, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096]),\n",
       " (7, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]),\n",
       " (8, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]),\n",
       " (9, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]),\n",
       " (10, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096]),\n",
       " (11, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]),\n",
       " (12, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192]),\n",
       " (13, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]),\n",
       " (14, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096]),\n",
       " (15, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]),\n",
       " (16, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]),\n",
       " (17, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]),\n",
       " (18, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096]),\n",
       " (19, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]),\n",
       " (20, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "from itertools import groupby\n",
    "\n",
    "def find_buffer_sizes(sample_rate: int, max_chunk_duration: int = 10) -> List[Tuple[int, int]]:\n",
    "    solutions = []\n",
    "    \n",
    "    # Iterate through the possible chunk durations (in seconds)\n",
    "    for chunk_duration in range(1, max_chunk_duration + 1):\n",
    "        required_samples = sample_rate * chunk_duration\n",
    "        \n",
    "        # Check for buffer sizes in the sequence 2^n that evenly divide the required samples\n",
    "        for n in range(1, 15):\n",
    "            buffer_size = 2**n\n",
    "            if required_samples % buffer_size == 0:\n",
    "                solutions.append((chunk_duration, buffer_size))\n",
    "\n",
    "    # group on chunk duration\n",
    "    solutions = groupby(solutions, key=lambda x: x[0])\n",
    "    solutions = [(chunk_duration, list(size for _, size in sizes)) for chunk_duration, sizes in solutions]\n",
    "    return solutions\n",
    "\n",
    "# Sample rate of 44,100\n",
    "sample_rate = 256000\n",
    "\n",
    "# Finding possible solutions\n",
    "solutions = find_buffer_sizes(sample_rate, max_chunk_duration=20)\n",
    "solutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17066666666666666"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8192/48_000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
