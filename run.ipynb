{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "path = os.getcwd()\n",
    "# path = 'dist'\n",
    "\n",
    "no_formatting = True\n",
    "print_token_counts = False\n",
    "\n",
    "comment_symbol = \"//\"\n",
    "lang = \"typescript\"\n",
    "\n",
    "ignore_dirs = [\"node_modules\", \".git\", \".vscode\", \"__pycache__\", \"old\", \"test_page\", \"dist\"]\n",
    "ignore_files = [\"example.ts\", \"output.txt\", \"yarn.lock\", \"package-lock.json\", \"package.json\", \"tsconfig.json\", \"run.ipynb\", \"tailwind.config.cjs\"]\n",
    "allowed_extensions = (\"pin\")\n",
    "ignored_extensions = (\".ipynb\")\n",
    "\n",
    "\n",
    "target_files = []\n",
    "# target_files = []\n",
    "\n",
    "\n",
    "\n",
    "encode = tiktoken.encoding_for_model(\"gpt-3.5-turbo\").encode\n",
    "count_token = lambda x: len(encode(x))\n",
    "\n",
    "def generate_tree(start_path, ignore_dirs = ignore_dirs):\n",
    "    tree = \"\"\n",
    "    for root, dirs, files in os.walk(start_path):\n",
    "        # ignore dirs\n",
    "        for ignore_dir in ignore_dirs:\n",
    "            if ignore_dir in dirs:\n",
    "                dirs.remove(ignore_dir)\n",
    "            \n",
    "        level = root.replace(start_path, '').count(os.sep)\n",
    "        indent = ' ' * 1 * (level)\n",
    "        tree += f\"{indent}{os.path.basename(root)}/\\n\"\n",
    "        sub_indent = ' ' * 1 * (level + 1)\n",
    "        for f in files:\n",
    "            tree += f\"{sub_indent}{f}\\n\"\n",
    "    return tree[:-1]\n",
    "\n",
    "def walk_files(\n",
    "    path = os.getcwd(), \n",
    "    target_files=target_files, \n",
    "    output_file = \"output.txt\", \n",
    "    lang=\"typescript\", \n",
    "    ignore_dirs = ignore_dirs, \n",
    "    print_token_counts = True, \n",
    "    ignore_files = ignore_files, \n",
    "    comment_symbol = \"//\", \n",
    "    allowed_extensions = allowed_extensions, \n",
    "    ignored_extensions = ignored_extensions, \n",
    "    no_formatting = no_formatting\n",
    "    ):\n",
    "    zero_target_files = target_files == []\n",
    "    zero_allowed_extensions = allowed_extensions == ()\n",
    "\n",
    "    cwd = os.getcwd()\n",
    "    outputs = []\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for ignore_dir in ignore_dirs:\n",
    "            if ignore_dir in dirs:\n",
    "                dirs.remove(ignore_dir)\n",
    "\n",
    "        for file in files:\n",
    "            if zero_allowed_extensions or file.endswith(allowed_extensions) and not file.endswith(ignored_extensions):\n",
    "                if file in ignore_files:\n",
    "                    continue\n",
    "                if zero_target_files or file in target_files:\n",
    "                    with open(os.path.join(root, file), \"r\") as infile:\n",
    "                        if no_formatting:\n",
    "                            relative_path = f'{root.replace(cwd, \"\")}/{file}'\n",
    "                            # if the relative path starts with a /, remove it\n",
    "                            if relative_path[0] == '/':\n",
    "                                relative_path = relative_path[1:]\n",
    "                            try: \n",
    "                                data = infile.read()\n",
    "                            except:\n",
    "                                print(f\"Error reading {relative_path}\")\n",
    "                                continue\n",
    "                            comment_pattern = re.escape(comment_symbol) + '.*$'\n",
    "                            data = re.sub(comment_pattern, ' ', data, flags=re.MULTILINE)\n",
    "                            data = re.sub( r'(?<=\\n)[ \\t]+(?=\\n)', '', data)\n",
    "                            data = re.sub('\\n+', ';', data)\n",
    "\n",
    "                            data = data.replace(';', '; ')\n",
    "                            data = re.sub(r' +', ' ', data)\n",
    "\n",
    "                            if print_token_counts:\n",
    "                                token_count = count_token(data) + count_token(relative_path)\n",
    "                            else:\n",
    "                                token_count = 0\n",
    "                                                \n",
    "                            output = {\n",
    "                                \"path\": relative_path,\n",
    "                                \"token_count\": token_count,\n",
    "                                \"data\": data\n",
    "                            }\n",
    "                        else:\n",
    "                            try: \n",
    "                                data = infile.read()\n",
    "                            except:\n",
    "                                print(f\"Error reading {relative_path}\")\n",
    "                                continue\n",
    "\n",
    "                            relative_path = f'{root.replace(cwd, \"\")}/{file}'\n",
    "                            # if the relative path starts with a /, remove it\n",
    "                            if relative_path[0] == '/':\n",
    "                                relative_path = relative_path[1:]\n",
    "\n",
    "                            if print_token_counts:\n",
    "                                token_count = count_token(data) + count_token(relative_path)\n",
    "                            else:\n",
    "                                token_count = 0\n",
    "                                                \n",
    "                            output = {\n",
    "                                \"path\": relative_path,\n",
    "                                \"token_count\": token_count,\n",
    "                                \"data\": data\n",
    "                            }\n",
    "\n",
    "                        if len(data) > 0:\n",
    "                            outputs.append(output)\n",
    "\n",
    "    \n",
    "    outputs = sorted(outputs, key=lambda x: x['path'].split('.')[-1])\n",
    "    sept = '\\n\\n---\\n\\n'\n",
    "    tree = generate_tree(path) + sept\n",
    "\n",
    "    total_token_count = count_token(''.join([x['data'] for x in outputs]) + tree)\n",
    "\n",
    "    # output_content = f'```{lang}\\n{data}\\n```'\n",
    "    generate_output_content = lambda x: f\"```{lang}\\n{comment_symbol} {x['path']}\\n{x['data']}\\n```\"\n",
    "\n",
    "    if print_token_counts:\n",
    "        out_string = tree + sept.join([f\"count: {x['token_count']}\\n{generate_output_content(x)}\" for x in outputs])\n",
    "    else:\n",
    "        out_string = tree + sept.join([generate_output_content(x) for x in outputs])\n",
    "\n",
    "    with open(output_file, \"w\") as outfile:\n",
    "        outfile.write(f'Total token count: {total_token_count}\\n\\n{out_string}')\n",
    "\n",
    "walk_files(path, print_token_counts = print_token_counts, comment_symbol = comment_symbol, lang = lang)\n",
    "os.system(\"code output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://ls7ojkm1lh.execute-api.us-west-2.amazonaws.com/Prod'\n",
    "# headers = {\n",
    "#     \"Content-Type\": \"application/json\",\n",
    "#     \"x-api-key\": \"evEol4JklL9AGHHijU03j4kGctKFg79d3tJb1zBh\",\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159416\n",
      "{'error': 'Unexpected error: can only concatenate str (not \"NoneType\") to str'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import json\n",
    "import base64\n",
    "\n",
    "# load old/devEnv/base64/example.txt\n",
    "with open('old/devEnv/base64/example.txt', 'r') as f:\n",
    "    base64_audio = f.read()\n",
    "    \n",
    "print(len(base64_audio))\n",
    "\n",
    "# lang = 'hi'\n",
    "lang = 'pt'\n",
    "# lang = 'ko'\n",
    "\n",
    "url = 'https://dyhweydzb4ws7peuxwmy5dzifm0zhnww.lambda-url.us-west-2.on.aws/'\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"audioData\": base64_audio,\n",
    "    \"startTime\": 0,\n",
    "    \"endTime\": 10,\n",
    "    \"sourceLanguage\": \"en\",\n",
    "    \"targetLanguage\": lang,\n",
    "    \"videoURL\": \"http://example.com/video.mp4\",\n",
    "    \"videoId\": \"test\"\n",
    "}\n",
    "\n",
    "jsonData = json.dumps(data)\n",
    "response = requests.post(url, headers=headers, data=jsonData)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    content = response.json()\n",
    "    print(response.__dict__)\n",
    "    audioDataTrans = content['audioData']\n",
    "    # convert back into binary\n",
    "    audioDataTrans = base64.b64decode(audioDataTrans)\n",
    "    # save to mp3 file\n",
    "    outpit_file_name = f'old/devEnv/test_audio_{lang}.mp3'\n",
    "    with open(outpit_file_name, 'wb') as f:\n",
    "        f.write(audioDataTrans)\n",
    "    print('success')\n",
    "else:\n",
    "    print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Unknown file type'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "import filetype\n",
    "import re\n",
    "\n",
    "def identify_file_type(base64_string):\n",
    "    # Decode the base64 string to bytes\n",
    "    actual_base64_data = base64_string.split(\",\")[-1]\n",
    "    \n",
    "    # Check if padding adjustment is necessary\n",
    "    missing_padding = len(actual_base64_data) % 4\n",
    "    if missing_padding:\n",
    "        actual_base64_data += '=' * (4 - missing_padding)\n",
    "    \n",
    "    # Ensure the base64 string is valid\n",
    "    if not re.fullmatch(r'[A-Za-z0-9+/]*={0,2}', actual_base64_data):\n",
    "        return \"Invalid base64 string\"\n",
    "\n",
    "    binary_data = base64.b64decode(actual_base64_data)\n",
    "    \n",
    "    kind = filetype.guess(binary_data)\n",
    "\n",
    "    if kind is None:\n",
    "        return \"Unknown file type\"\n",
    "    else:\n",
    "        return kind.extension\n",
    "\n",
    "\n",
    "with open('old/devEnv/base64/example.txt', 'r') as f:\n",
    "    base64_audio = f.read()\n",
    "    \n",
    "identify_file_type(base64_audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_extension(mime_type_str):\n",
    "    codec_to_extension_map = {\n",
    "        'opus': '.opus',\n",
    "        'vorbis': '.ogg',\n",
    "        'mp4a.40.2': '.m4a',\n",
    "        'mpeg3': '.mp3',\n",
    "        'flac': '.flac',\n",
    "        'alac': '.m4a',\n",
    "        '1': '.wav',    # PCM codec for wav\n",
    "        'samr': '.amr',\n",
    "        'mp4v.20.8': '.mp4',\n",
    "        'XVID': '.avi',\n",
    "        'wmv3': '.wmv',\n",
    "        'vp9': '.webm',\n",
    "        'vp8': '.webm',\n",
    "        'V_MPEG4/ISO/AVC': '.mkv',\n",
    "        'theora': '.ogg',\n",
    "        'mpeg1video': '.mpg',\n",
    "        'A_AAC': '.aac',\n",
    "        'oga': '.oga'    # Ogg Vorbis audio\n",
    "    }\n",
    "\n",
    "    # Split on semicolon to get the base mime type and parameters\n",
    "    parts = mime_type_str.split(';')\n",
    "    base_mime_type = parts[0]\n",
    "    base_type, subtype = base_mime_type.split('/')\n",
    "\n",
    "    # If there's no semicolon, we guess the extension based on the subtype\n",
    "    if len(parts) < 2:\n",
    "        return codec_to_extension_map.get(subtype, f\".{subtype}\")\n",
    "\n",
    "    params = parts[1]\n",
    "    \n",
    "    # Extract the codec from the parameters, if it exists\n",
    "    if 'codecs=' in params:\n",
    "        codecs = params.split('codecs=')[1].replace('\"', '').split(',')\n",
    "        \n",
    "        # if there are multiple codecs, we assume the second one is the audio codec\n",
    "        if len(codecs) > 1:\n",
    "            audio_codec = codecs[1].strip()\n",
    "        else:\n",
    "            audio_codec = codecs[0].strip()\n",
    "            \n",
    "        return codec_to_extension_map.get(audio_codec, f\".{subtype}\")\n",
    "\n",
    "    # If there's no codec, return based on the subtype\n",
    "    else:\n",
    "        return codec_to_extension_map.get(subtype, f\".{subtype}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_mime_types = [\n",
    "    'video/webm; codecs=\"vp9, opus\"',\n",
    "    'video/mp4; codecs=\"avc1.42E01E, mp4a.40.2\"',\n",
    "    'video/avc; codecs=\"avc1.42E01E, mp4a.40.2\"',\n",
    "    'video/webm; codecs=\"vp8, vorbis\"',\n",
    "    'video/mp4; codecs=\"hev1.1.2.L93.B0, mp4a.40.2\"',\n",
    "    'video/quicktime; codecs=\"avc1.42E01E, mp4a.40.2\"',\n",
    "    'video/x-matroska; codecs=\"V_MPEG4/ISO/AVC, A_AAC\"',\n",
    "    'video/ogg; codecs=\"theora, vorbis\"',\n",
    "    'video/3gpp; codecs=\"mp4v.20.8, samr\"',\n",
    "    'video/mpeg; codecs=\"mpeg1video\"',\n",
    "    'video/x-m4v; codecs=\"avc1.42E01E, mp4a.40.2\"',\n",
    "    'video/x-msvideo; codecs=\"XVID\"',\n",
    "    'video/x-ms-wmv; codecs=\"wmv3\"',\n",
    "]\n",
    "\n",
    "audioMimeTypes = [\n",
    "  \"audio/webm; codecs=opus\",          \n",
    "  \"audio/mp4; codecs=mp4a.40.2\",      \n",
    "  \"audio/aac; codecs=mp4a.40.2\",      \n",
    "  \"audio/mpeg; codecs=mpeg3\",\n",
    "  \"audio/ogg; codecs=vorbis\",\n",
    "  \"audio/flac\",\n",
    "  \"audio/alac\",\n",
    "  \"audio/wav; codecs=1\", \n",
    "  \"audio/amr\",\n",
    "]\n",
    "\n",
    "# test every mime type and print the result\n",
    "for mime_type_str in video_mime_types + audioMimeTypes:\n",
    "    audio_extension = get_audio_extension(mime_type_str)\n",
    "    print(f'{mime_type_str} -> {audio_extension}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytube\n",
    "\n",
    "url = 'https://www.youtube.com/watch?v=VTOO_9_ECA8'\n",
    "\n",
    "video = pytube.YouTube(url)\n",
    "streams = video.streams\n",
    "\n",
    "# download the video\n",
    "video.streams.get_highest_resolution().download()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy\n",
    "# vid.mp4\n",
    "\n",
    "# Get 59s to 1:22s\n",
    "\n",
    "# load with moviepy\n",
    "from moviepy.editor import VideoFileClip\n",
    "clip = VideoFileClip(\"vid.mp4\").subclip(59, 82)\n",
    "\n",
    "# save as mp4\n",
    "clip.write_videofile(\"vid2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the magic numbers for common audio file formats\n",
    "magic_numbers = {\n",
    "    \"mp3\": [\"494433\", \"fff3\", \"fffb\"],\n",
    "    \"wav\": [\"52494646\"],\n",
    "    \"ogg\": [\"4f676753\"],\n",
    "    \"flac\": [\"664c6143\"],\n",
    "    \"aac\": [\"fff1\", \"fff9\", \"fff3\", \"fffd\"],\n",
    "    \"wma\": [\"3026b275\"],\n",
    "    \"midi\": [\"4d546864\"],\n",
    "    \"aiff\": [\"464f524d\"],\n",
    "}\n",
    "\n",
    "# Convert the first few bytes of the binary content to hexadecimal\n",
    "hex_signature = binary_content[:4].hex()\n",
    "\n",
    "# Function to identify the file type from the magic number\n",
    "def identify_file_type(hex_signature, magic_numbers):\n",
    "    for file_type, signatures in magic_numbers.items():\n",
    "        if any(hex_signature.startswith(sig) for sig in signatures):\n",
    "            return file_type\n",
    "    return \"Unknown file type\"\n",
    "\n",
    "# Identify the file type\n",
    "file_type = identify_file_type(hex_signature, magic_numbers)\n",
    "file_type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// Define the magic numbers for common audio file formats\n",
    "const magicNumbers: { [key: string]: string[] } = {\n",
    "    mp3: [\"494433\", \"fff3\", \"fffb\"],\n",
    "    wav: [\"52494646\"],\n",
    "    ogg: [\"4f676753\"],\n",
    "    flac: [\"664c6143\"],\n",
    "    aac: [\"fff1\", \"fff9\", \"fff3\", \"fffd\"],\n",
    "    wma: [\"3026b275\"],\n",
    "    midi: [\"4d546864\"],\n",
    "    aiff: [\"464f524d\"],\n",
    "};\n",
    "\n",
    "// Assume you have binaryContent as an ArrayBuffer or Buffer\n",
    "// Convert the first few bytes of the binary content to hexadecimal\n",
    "const hexSignature = binaryContent.slice(0, 4).toString('hex');\n",
    "\n",
    "// Function to identify the file type from the magic number\n",
    "function identifyFileType(hexSignature: string, magicNumbers: { [key: string]: string[] }): string {\n",
    "    for (const [fileType, signatures] of Object.entries(magicNumbers)) {\n",
    "        if (signatures.some(sig => hexSignature.startsWith(sig))) {\n",
    "            return fileType;\n",
    "        }\n",
    "    }\n",
    "    return \"Unknown file type\";\n",
    "}\n",
    "\n",
    "// Identify the file type\n",
    "const fileType = identifyFileType(hexSignature, magicNumbers);\n",
    "console.log(fileType);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install filetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]),\n",
       " (2, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096]),\n",
       " (3, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]),\n",
       " (4, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192]),\n",
       " (5, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]),\n",
       " (6, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096]),\n",
       " (7, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]),\n",
       " (8, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]),\n",
       " (9, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]),\n",
       " (10, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096]),\n",
       " (11, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]),\n",
       " (12, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192]),\n",
       " (13, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]),\n",
       " (14, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096]),\n",
       " (15, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]),\n",
       " (16, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]),\n",
       " (17, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]),\n",
       " (18, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096]),\n",
       " (19, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]),\n",
       " (20, [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "from itertools import groupby\n",
    "\n",
    "def find_buffer_sizes(sample_rate: int, max_chunk_duration: int = 10) -> List[Tuple[int, int]]:\n",
    "    solutions = []\n",
    "    \n",
    "    # Iterate through the possible chunk durations (in seconds)\n",
    "    for chunk_duration in range(1, max_chunk_duration + 1):\n",
    "        required_samples = sample_rate * chunk_duration\n",
    "        \n",
    "        # Check for buffer sizes in the sequence 2^n that evenly divide the required samples\n",
    "        for n in range(1, 15):\n",
    "            buffer_size = 2**n\n",
    "            if required_samples % buffer_size == 0:\n",
    "                solutions.append((chunk_duration, buffer_size))\n",
    "\n",
    "    # group on chunk duration\n",
    "    solutions = groupby(solutions, key=lambda x: x[0])\n",
    "    solutions = [(chunk_duration, list(size for _, size in sizes)) for chunk_duration, sizes in solutions]\n",
    "    return solutions\n",
    "\n",
    "# Sample rate of 44,100\n",
    "sample_rate = 256000\n",
    "\n",
    "# Finding possible solutions\n",
    "solutions = find_buffer_sizes(sample_rate, max_chunk_duration=20)\n",
    "solutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17066666666666666"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8192/48_000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
